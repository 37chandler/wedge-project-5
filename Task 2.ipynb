{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 there was an error operating on 'projects/umt-msba/locations/us/sessions/CAISDDB3UjNrem1EX19iOBoCanIaAmpk/streams/GgJqchoCamQoAg': the user does not have 'bigquery.readsessions.getData' permission for 'projects/umt-msba/locations/us/sessions/CAISDDB3UjNrem1EX19iOBoCanIaAmpk/streams/GgJqchoCamQoAg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:165\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m     prefetch_first \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callable_, \u001b[39m\"\u001b[39m\u001b[39m_prefetch_first_result_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 165\u001b[0m     \u001b[39mreturn\u001b[39;00m _StreamingResponseIterator(\n\u001b[0;32m    166\u001b[0m         result, prefetch_first_result\u001b[39m=\u001b[39mprefetch_first\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:91\u001b[0m, in \u001b[0;36m_StreamingResponseIterator.__init__\u001b[1;34m(self, wrapped, prefetch_first_result)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m prefetch_first_result:\n\u001b[1;32m---> 91\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stored_first_result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrapped)\n\u001b[0;32m     92\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     \u001b[39m# It is possible the wrapped method isn't an iterable (a grpc.Call\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[39m# for instance). If this happens don't store the first result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\grpc\\_channel.py:541\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 541\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next()\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\grpc\\_channel.py:967\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"there was an error operating on 'projects/umt-msba/locations/us/sessions/CAISDDB3UjNrem1EX19iOBoCanIaAmpk/streams/GgJqchoCamQoAg': the user does not have 'bigquery.readsessions.getData' permission for 'projects/umt-msba/locations/us/sessions/CAISDDB3UjNrem1EX19iOBoCanIaAmpk/streams/GgJqchoCamQoAg'\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.69.234:443 {grpc_message:\"there was an error operating on \\'projects/umt-msba/locations/us/sessions/CAISDDB3UjNrem1EX19iOBoCanIaAmpk/streams/GgJqchoCamQoAg\\': the user does not have \\'bigquery.readsessions.getData\\' permission for \\'projects/umt-msba/locations/us/sessions/CAISDDB3UjNrem1EX19iOBoCanIaAmpk/streams/GgJqchoCamQoAg\\'\", grpc_status:7, created_time:\"2023-11-30T20:42:23.324885+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jandr\\OneDrive\\Desktop\\ADA\\wedge-project\\wedge-project\\code\\Task 2.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jandr/OneDrive/Desktop/ADA/wedge-project/wedge-project/code/Task%202.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Run the query and save the results to a pandas DataFrame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jandr/OneDrive/Desktop/ADA/wedge-project/wedge-project/code/Task%202.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m query_job \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mquery(sql)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jandr/OneDrive/Desktop/ADA/wedge-project/wedge-project/code/Task%202.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m results \u001b[39m=\u001b[39m query_job\u001b[39m.\u001b[39mto_dataframe()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jandr/OneDrive/Desktop/ADA/wedge-project/wedge-project/code/Task%202.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m results\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1860\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[1;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype)\u001b[0m\n\u001b[0;32m   1710\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \n\u001b[0;32m   1712\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1857\u001b[0m \u001b[39m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m query_result \u001b[39m=\u001b[39m wait_for_query(\u001b[39mself\u001b[39m, progress_bar_type, max_results\u001b[39m=\u001b[39mmax_results)\n\u001b[1;32m-> 1860\u001b[0m \u001b[39mreturn\u001b[39;00m query_result\u001b[39m.\u001b[39mto_dataframe(\n\u001b[0;32m   1861\u001b[0m     bqstorage_client\u001b[39m=\u001b[39mbqstorage_client,\n\u001b[0;32m   1862\u001b[0m     dtypes\u001b[39m=\u001b[39mdtypes,\n\u001b[0;32m   1863\u001b[0m     progress_bar_type\u001b[39m=\u001b[39mprogress_bar_type,\n\u001b[0;32m   1864\u001b[0m     create_bqstorage_client\u001b[39m=\u001b[39mcreate_bqstorage_client,\n\u001b[0;32m   1865\u001b[0m     geography_as_object\u001b[39m=\u001b[39mgeography_as_object,\n\u001b[0;32m   1866\u001b[0m     bool_dtype\u001b[39m=\u001b[39mbool_dtype,\n\u001b[0;32m   1867\u001b[0m     int_dtype\u001b[39m=\u001b[39mint_dtype,\n\u001b[0;32m   1868\u001b[0m     float_dtype\u001b[39m=\u001b[39mfloat_dtype,\n\u001b[0;32m   1869\u001b[0m     string_dtype\u001b[39m=\u001b[39mstring_dtype,\n\u001b[0;32m   1870\u001b[0m     date_dtype\u001b[39m=\u001b[39mdate_dtype,\n\u001b[0;32m   1871\u001b[0m     datetime_dtype\u001b[39m=\u001b[39mdatetime_dtype,\n\u001b[0;32m   1872\u001b[0m     time_dtype\u001b[39m=\u001b[39mtime_dtype,\n\u001b[0;32m   1873\u001b[0m     timestamp_dtype\u001b[39m=\u001b[39mtimestamp_dtype,\n\u001b[0;32m   1874\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:2153\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[1;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype)\u001b[0m\n\u001b[0;32m   2150\u001b[0m     create_bqstorage_client \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   2151\u001b[0m     bqstorage_client \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2153\u001b[0m record_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_arrow(\n\u001b[0;32m   2154\u001b[0m     progress_bar_type\u001b[39m=\u001b[39mprogress_bar_type,\n\u001b[0;32m   2155\u001b[0m     bqstorage_client\u001b[39m=\u001b[39mbqstorage_client,\n\u001b[0;32m   2156\u001b[0m     create_bqstorage_client\u001b[39m=\u001b[39mcreate_bqstorage_client,\n\u001b[0;32m   2157\u001b[0m )\n\u001b[0;32m   2159\u001b[0m \u001b[39m# Default date dtype is `db_dtypes.DateDtype()` that could cause out of bounds error,\u001b[39;00m\n\u001b[0;32m   2160\u001b[0m \u001b[39m# when pyarrow converts date values to nanosecond precision. To avoid the error, we\u001b[39;00m\n\u001b[0;32m   2161\u001b[0m \u001b[39m# set the date_as_object parameter to True, if necessary.\u001b[39;00m\n\u001b[0;32m   2162\u001b[0m date_as_object \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1823\u001b[0m, in \u001b[0;36mRowIterator.to_arrow\u001b[1;34m(self, progress_bar_type, bqstorage_client, create_bqstorage_client)\u001b[0m\n\u001b[0;32m   1818\u001b[0m progress_bar \u001b[39m=\u001b[39m get_progress_bar(\n\u001b[0;32m   1819\u001b[0m     progress_bar_type, \u001b[39m\"\u001b[39m\u001b[39mDownloading\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_rows, \u001b[39m\"\u001b[39m\u001b[39mrows\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1820\u001b[0m )\n\u001b[0;32m   1822\u001b[0m record_batches \u001b[39m=\u001b[39m []\n\u001b[1;32m-> 1823\u001b[0m \u001b[39mfor\u001b[39;00m record_batch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_arrow_iterable(\n\u001b[0;32m   1824\u001b[0m     bqstorage_client\u001b[39m=\u001b[39mbqstorage_client\n\u001b[0;32m   1825\u001b[0m ):\n\u001b[0;32m   1826\u001b[0m     record_batches\u001b[39m.\u001b[39mappend(record_batch)\n\u001b[0;32m   1828\u001b[0m     \u001b[39mif\u001b[39;00m progress_bar \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1829\u001b[0m         \u001b[39m# In some cases, the number of total rows is not populated\u001b[39;00m\n\u001b[0;32m   1830\u001b[0m         \u001b[39m# until the first page of rows is fetched. Update the\u001b[39;00m\n\u001b[0;32m   1831\u001b[0m         \u001b[39m# progress bar's total to keep an accurate count.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1686\u001b[0m, in \u001b[0;36mRowIterator._to_page_iterable\u001b[1;34m(self, bqstorage_download, tabledata_list_download, bqstorage_client)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     bqstorage_client \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m result_pages \u001b[39m=\u001b[39m (\n\u001b[0;32m   1682\u001b[0m     bqstorage_download()\n\u001b[0;32m   1683\u001b[0m     \u001b[39mif\u001b[39;00m bqstorage_client \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1684\u001b[0m     \u001b[39melse\u001b[39;00m tabledata_list_download()\n\u001b[0;32m   1685\u001b[0m )\n\u001b[1;32m-> 1686\u001b[0m \u001b[39myield from\u001b[39;00m result_pages\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:874\u001b[0m, in \u001b[0;36m_download_table_bqstorage\u001b[1;34m(project_id, table, bqstorage_client, preserve_order, selected_fields, page_to_item, max_queue_size)\u001b[0m\n\u001b[0;32m    870\u001b[0m done, not_done \u001b[39m=\u001b[39m _nowait(not_done)\n\u001b[0;32m    871\u001b[0m \u001b[39mfor\u001b[39;00m future \u001b[39min\u001b[39;00m done:\n\u001b[0;32m    872\u001b[0m     \u001b[39m# Call result() on any finished threads to raise any\u001b[39;00m\n\u001b[0;32m    873\u001b[0m     \u001b[39m# exceptions encountered.\u001b[39;00m\n\u001b[1;32m--> 874\u001b[0m     future\u001b[39m.\u001b[39mresult()\n\u001b[0;32m    876\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     frame \u001b[39m=\u001b[39m worker_queue\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m_PROGRESS_INTERVAL)\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:743\u001b[0m, in \u001b[0;36m_download_table_bqstorage_stream\u001b[1;34m(download_state, bqstorage_client, session, stream, worker_queue, page_to_item)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_table_bqstorage_stream\u001b[39m(\n\u001b[0;32m    741\u001b[0m     download_state, bqstorage_client, session, stream, worker_queue, page_to_item\n\u001b[0;32m    742\u001b[0m ):\n\u001b[1;32m--> 743\u001b[0m     reader \u001b[39m=\u001b[39m bqstorage_client\u001b[39m.\u001b[39mread_rows(stream\u001b[39m.\u001b[39mname)\n\u001b[0;32m    745\u001b[0m     \u001b[39m# Avoid deprecation warnings for passing in unnecessary read session.\u001b[39;00m\n\u001b[0;32m    746\u001b[0m     \u001b[39m# https://github.com/googleapis/python-bigquery-storage/issues/229\u001b[39;00m\n\u001b[0;32m    747\u001b[0m     \u001b[39mif\u001b[39;00m _versions_helpers\u001b[39m.\u001b[39mBQ_STORAGE_VERSIONS\u001b[39m.\u001b[39mis_read_session_optional:\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery_storage_v1\\client.py:139\u001b[0m, in \u001b[0;36mBigQueryReadClient.read_rows\u001b[1;34m(self, name, offset, retry, timeout, metadata, retry_delay_callback)\u001b[0m\n\u001b[0;32m    131\u001b[0m gapic_client \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(BigQueryReadClient, \u001b[39mself\u001b[39m)\n\u001b[0;32m    132\u001b[0m stream \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39mReadRowsStream(\n\u001b[0;32m    133\u001b[0m     gapic_client,\n\u001b[0;32m    134\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m     retry_delay_callback\u001b[39m=\u001b[39mretry_delay_callback,\n\u001b[0;32m    138\u001b[0m )\n\u001b[1;32m--> 139\u001b[0m stream\u001b[39m.\u001b[39m_reconnect()\n\u001b[0;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery_storage_v1\\reader.py:178\u001b[0m, in \u001b[0;36mReadRowsStream._reconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mread_rows(\n\u001b[0;32m    179\u001b[0m             read_stream\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name,\n\u001b[0;32m    180\u001b[0m             offset\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset,\n\u001b[0;32m    181\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_rows_kwargs\n\u001b[0;32m    182\u001b[0m         )\n\u001b[0;32m    183\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery_storage_v1\\services\\big_query_read\\client.py:757\u001b[0m, in \u001b[0;36mBigQueryReadClient.read_rows\u001b[1;34m(self, request, read_stream, offset, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    750\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(metadata) \u001b[39m+\u001b[39m (\n\u001b[0;32m    751\u001b[0m     gapic_v1\u001b[39m.\u001b[39mrouting_header\u001b[39m.\u001b[39mto_grpc_metadata(\n\u001b[0;32m    752\u001b[0m         ((\u001b[39m\"\u001b[39m\u001b[39mread_stream\u001b[39m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mread_stream),)\n\u001b[0;32m    753\u001b[0m     ),\n\u001b[0;32m    754\u001b[0m )\n\u001b[0;32m    756\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[0;32m    758\u001b[0m     request,\n\u001b[0;32m    759\u001b[0m     retry\u001b[39m=\u001b[39mretry,\n\u001b[0;32m    760\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    761\u001b[0m     metadata\u001b[39m=\u001b[39mmetadata,\n\u001b[0;32m    762\u001b[0m )\n\u001b[0;32m    764\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry.py:372\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    369\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    370\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[0;32m    371\u001b[0m )\n\u001b[1;32m--> 372\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    373\u001b[0m     target,\n\u001b[0;32m    374\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predicate,\n\u001b[0;32m    375\u001b[0m     sleep_generator,\n\u001b[0;32m    376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout,\n\u001b[0;32m    377\u001b[0m     on_error\u001b[39m=\u001b[39mon_error,\n\u001b[0;32m    378\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry.py:207\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[0;32m    206\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m         result \u001b[39m=\u001b[39m target()\n\u001b[0;32m    208\u001b[0m         \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misawaitable(result):\n\u001b[0;32m    209\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[39m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout \u001b[39m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jandr\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:169\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m _StreamingResponseIterator(\n\u001b[0;32m    166\u001b[0m         result, prefetch_first_result\u001b[39m=\u001b[39mprefetch_first\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m--> 169\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mPermissionDenied\u001b[0m: 403 there was an error operating on 'projects/umt-msba/locations/us/sessions/CAISDDB3UjNrem1EX19iOBoCanIaAmpk/streams/GgJqchoCamQoAg': the user does not have 'bigquery.readsessions.getData' permission for 'projects/umt-msba/locations/us/sessions/CAISDDB3UjNrem1EX19iOBoCanIaAmpk/streams/GgJqchoCamQoAg'"
     ]
    }
   ],
   "source": [
    "# Set up your BigQuery client\n",
    "client = bigquery.Client(project='umt-msba')\n",
    "\n",
    "# Your SQL query\n",
    "sql = \"\"\"\n",
    "WITH sample_cte AS (\n",
    "  SELECT DISTINCT card_no\n",
    "  FROM `umt-msba.transactions.transArchive_*`\n",
    "  WHERE card_no != 3\n",
    "  ORDER BY RAND()\n",
    "  LIMIT 500\n",
    ")\n",
    "SELECT *\n",
    "FROM `umt-msba.wedge_transactions.transArchive_*` AS trans\n",
    "JOIN sample_cte\n",
    "ON sample_cte.card_no = trans.card_no\n",
    "\"\"\"\n",
    "\n",
    "# Run the query and save the results to a pandas DataFrame\n",
    "query_job = client.query(sql)\n",
    "results = query_job.to_dataframe()\n",
    "\n",
    "results.head()\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "#results.to_csv('query_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
